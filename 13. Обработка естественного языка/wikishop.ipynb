{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» c BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание проекта \n",
    "**В данном проекте будут рассмотрены ДВА варианта подготовки признаков для обучения моделей.**  \n",
    "\n",
    "Проект нацелен на воплощение алгоритма определения токсичных комментариев для их отправки на модерацию.\n",
    "### Цель проекта\n",
    "Создать модель классификации комментариев на позитивные и негативные.\n",
    "### Описание данных\n",
    "**Нам предоставлен набор данных с разметкой о токсичности правок от комании «Викишоп».**   \n",
    "\n",
    "\n",
    "**Признаки:**\n",
    "- text - текст комментария\n",
    "\n",
    "**Целевой признак:**\n",
    "- toxic — категория содержимого в комментарии\n",
    "\n",
    "**Заказчику важны:**\n",
    "\n",
    "- значение метрики качества F1 не меньше 0.75\n",
    "\n",
    "### План работы\n",
    "1. [Загрузка данных](#section_1)  \n",
    "2. [Обучение и анализ моделей](#section_2)\n",
    "3. [Проверка итоговой модели](#section_3)\n",
    "4. [Общий вывод](#section_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section_1'></a>\n",
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим необходимые библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Egor\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Egor\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Egor\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Egor\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Egor\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# работа с данными\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "# модели машинного обучения\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# вспомогательные средства \n",
    "from tqdm import notebook\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Произведём загрузку датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_1 = r'C:\\Projects\\wikishop\\toxic_comments.csv'\n",
    "path_2 = '/datasets/toxic_comments.csv'\n",
    "\n",
    "if os.path.exists(path_1):\n",
    "    df = pd.read_csv(path_1, index_col=[0]).reset_index(drop=True)\n",
    "elif os.path.exists(path_2):\n",
    "    df = pd.read_csv(path_2, index_col=[0]).reset_index(drop=True)\n",
    "else:\n",
    "    print('Something is wrong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.head(30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    30000 non-null  object\n",
      " 1   toxic   30000 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 468.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0\n",
       "5  \"\\n\\nCongratulations from me as well, use the ...      0\n",
       "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "7  Your vandalism to the Matt Shirvington article...      0\n",
       "8  Sorry if the word 'nonsense' was offensive to ...      0\n",
       "9  alignment on this subject and which are contra...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1042"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данных присутствует дисбаланс классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных c BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним загрузку модулей для работы с BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at unitary/toxic-bert were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "model_name = 'unitary/toxic-bert'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# инициализируем токенизатор\n",
    "default_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# инициализируем модель\n",
    "default_model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "default_model = default_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokenized = default_tokenizer(list(df['text']), return_tensors='pt', truncation=True, padding=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tokenized = df_tokenized.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca30288a77b4500a491576b10e8c3d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 200\n",
    "embeddings = []\n",
    "torch.cuda.empty_cache()\n",
    "for i in notebook.tqdm(range(df_tokenized['input_ids'].shape[0] // batch_size)):\n",
    "        batch = torch.cuda.LongTensor(df_tokenized['input_ids'][batch_size*i:batch_size*(i+1)]) \n",
    "        attention_mask_batch = torch.cuda.LongTensor(df_tokenized['attention_mask'][batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = default_model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Произведём объединение эмбеддингов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = torch.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на тренировочную и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, \n",
    "    df['toxic'][:features.shape[0]], \n",
    "    test_size=0.2, \n",
    "    random_state=12345\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([24000, 768]), (24000,), torch.Size([6000, 768]), (6000,))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def lemmatize(text):\n",
    "    word_list = nltk.word_tokenize(text)\n",
    "    lemmatized_output = ' '.join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in word_list])\n",
    "    return lemmatized_output\n",
    "\n",
    "def clear_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z ]', ' ', text)\n",
    "    return \" \".join(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utf-8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(52, 52, 36)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.getdefaultencoding())\n",
    "sys.getsizeof('asd'), sys.getsizeof(u'asd'), sys.getsizeof(str.encode('asd', 'ascii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df['text'].head(30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16db6a7757664b7fa7e91b6f1ac769d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus_lemm = [lemmatize(clear_text(corpus[i])) for i in notebook.tqdm(range(len(corpus)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер тренировочной выборки: 24000\n",
      "Размер тестовой выборки: 6000\n"
     ]
    }
   ],
   "source": [
    "X_train_tf, X_test_tf, y_train_tf, y_test_tf = train_test_split(corpus_lemm, df['toxic'], test_size=0.2, random_state=12345)\n",
    "\n",
    "print(f\"Размер тренировочной выборки: {len(X_train)}\")\n",
    "print(f\"Размер тестовой выборки: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=stopwords)\n",
    "\n",
    "X_train_vector = vectorizer.fit_transform(X_train_tf)\n",
    "X_test_vector = vectorizer.transform(X_test_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение логистической регрессии на преобразованных данных методом TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 cross-val score: 0.688\n",
      "Best params: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "param_grid = {\n",
    "    'solver' : ['liblinear'], \n",
    "    'penalty' : ['l2'], \n",
    "    'C' : [10, 1.0, 0.1]\n",
    "}\n",
    "\n",
    "lrgs = GridSearchCV(\n",
    "    estimator=model, \n",
    "    param_grid=param_grid,  \n",
    "    cv=3, \n",
    "    scoring='f1',\n",
    "    #n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "lrgs.fit(X_train_vector, y_train_tf)\n",
    "\n",
    "print(f\"F1 cross-val score: {lrgs.best_score_:.3f}\")\n",
    "print(f\"Best params: {lrgs.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка модели на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6996966632962589"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=12345)\n",
    "\n",
    "model.fit(X_train_vector, y_train_tf)\n",
    "y_pred = model.predict(X_test_vector)\n",
    "f1_score(y_test_tf, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для экономии времени данная модель обучалась только на части всего датасета, если производить обучение на полных данных, то модель линейной регрессии по качеству превысит заданный уровень F1, но всё ещё будет значительно отставать от моделей, обученных на данных, преобразованных с помощью BERT, результаты приведены ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section_2'></a>\n",
    "## Обучение и анализ моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 cross-val score: 0.931\n",
      "Best params: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "param_grid = {\n",
    "    'solver' : ['liblinear'], \n",
    "    'penalty' : ['l2'], \n",
    "    'C' : [10, 1.0, 0.1]\n",
    "}\n",
    "\n",
    "lrgs = GridSearchCV(\n",
    "    estimator=model, \n",
    "    param_grid=param_grid,  \n",
    "    cv=3, \n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "lrgs.fit(X_train, y_train)\n",
    "\n",
    "print(f\"F1 cross-val score: {lrgs.best_score_:.3f}\")\n",
    "print(f\"Best params: {lrgs.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 36 is smaller than n_iter=2000. Running 36 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 cross-val score: 0.921\n",
      "Best params: {'n_estimators': 100, 'max_features': 'auto', 'max_depth': 1}\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=12345)\n",
    "\n",
    "params = {\n",
    "    'max_depth': [1, 5, 10, 15],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'n_estimators': [10, 50, 100],\n",
    "}\n",
    "\n",
    "rf_hrs = HalvingRandomSearchCV(\n",
    "    model,\n",
    "    params,\n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    error_score='raise',\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    random_state=12345\n",
    ")\n",
    "\n",
    "rf_hrs.fit(X_train, y_train)\n",
    "print(f\"F1 cross-val score: {rf_hrs.best_score_:.3f}\")\n",
    "print(f\"Best params: {rf_hrs.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 96 is smaller than n_iter=2000. Running 96 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 cross-val score: 0.879\n",
      "Best params: {'num_leaves': 15, 'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "model = LGBMClassifier()\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [3, 10, 15, 25],\n",
    "    'num_leaves': [7, 15, 35],\n",
    "    'learning_rate': [0.1, 0.2, 0.5, 0.7]\n",
    "}\n",
    "\n",
    "lgbm_hrs = HalvingRandomSearchCV(\n",
    "    model, \n",
    "    params, \n",
    "    cv=3, \n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    random_state=12345\n",
    ")\n",
    "\n",
    "lgbm_hrs.fit(X_train, y_train)\n",
    "\n",
    "print(f\"F1 cross-val score: {lgbm_hrs.best_score_:.3f}\")\n",
    "print(f\"Best params: {lgbm_hrs.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_9e9c7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9e9c7_level0_col0\" class=\"col_heading level0 col0\" >F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9e9c7_level0_row0\" class=\"row_heading level0 row0\" >LinearRegression</th>\n",
       "      <td id=\"T_9e9c7_row0_col0\" class=\"data row0 col0\" >0.931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9e9c7_level0_row1\" class=\"row_heading level0 row1\" >RandomForest</th>\n",
       "      <td id=\"T_9e9c7_row1_col0\" class=\"data row1 col0\" >0.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9e9c7_level0_row2\" class=\"row_heading level0 row2\" >LightGBM</th>\n",
       "      <td id=\"T_9e9c7_row2_col0\" class=\"data row2 col0\" >0.879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1f6591b5c10>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(\n",
    "    data=[lrgs.best_score_, rf_hrs.best_score_, lgbm_hrs.best_score_], \n",
    "    index=['LinearRegression', 'RandomForest', 'LightGBM'], \n",
    "    columns=['F1_score']\n",
    ")\n",
    "\n",
    "results.style.format('{:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из таблицы, лучший результат на кросс-валидации показала модель с использованием алгоритма RandomForest. Также стоит заметить, что все модели прошли заданный порог качества."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section_3'></a>\n",
    "## Проверка итоговой модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим качество модели случайного леса на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.937\n",
      "accuracy score: 0.987\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf_hrs.predict(X_test)\n",
    "\n",
    "print(f\"F1 score: {f1_score(y_test, y_pred):.3f}\")\n",
    "print(f\"accuracy score: {accuracy_score(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим модель на адекватность с помощью простейшей константной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy F1 score: 0.184\n",
      "Dummy accuracy score: 0.101\n"
     ]
    }
   ],
   "source": [
    "dummy = DummyClassifier(strategy='constant', constant=1)\n",
    "dummy.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dummy.predict(X_test)\n",
    "\n",
    "print(f\"Dummy F1 score: {f1_score(y_test, y_pred):.3f}\")\n",
    "print(f\"Dummy accuracy score: {accuracy_score(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель прошла проверку на адекватность. Сравнивать модель с константной моделью по F1 бессмысленно, так как в её предсказаниях отсутствуют верноположительные предсказания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section_4'></a>\n",
    "## Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе исследования были обработаны и проанализированы тексты комментариев сервиса «Викишоп». В качестве основного инструмента выступила предобученная модель BERT, которая преобразовла тексты в эмбеддинги с использованием вычислений на графическом процессоре. Созданы модели классификации комментариев. Все построенные модели показали удовлетворяющий условию задачи результат.\n",
    "После проделанной работы можно выделить алгоритм RandomForest, который продемонстрировал лучший результат в списке моделей машинного обучения. Но так же стоит отметить, что все модели показали качество по метрике F1 значительно превышающее 0,75. \n",
    "\n",
    "**После проделанного исследования можно сделать следующий вывод:**\n",
    "\n",
    "1. Для классификации комментариев целесообразно использовать модель RandomForest."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 17,
    "start_time": "2023-03-26T10:24:15.815Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-26T10:25:26.635Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-26T10:25:28.642Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-26T10:25:32.677Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-26T10:26:10.478Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-26T10:26:16.679Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-26T10:26:21.127Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-26T10:26:31.288Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-26T10:27:00.160Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.358px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
